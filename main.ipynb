{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('Del-Immorechner': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52a0ed2a27bd158a96d2b86a96ae523699af9e326ee9991e8751eb1a6f3a1aa6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "## Bayesian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n"
   ]
  },
  {
   "source": [
    "# DEL Mini-Challenge 1\n",
    "Es sollen Immobillienobjekte klassifiziert werden. Von der FHNW haben wir einen Datensatz erhalten (Siehe beiliegendes EDA-Notebook), in denen wir vorraussagen sollen, um was für ein Wohnobjekt es sich handelt; Ist es ein Zimmer? Wohnung? Haus? Diese Challenge hatten wir gelöst, aber ohne Deep Learning.\n",
    "## Einführung\n",
    "### Lösung der Mini-Challenge 1 für DEL\n",
    "Wir benutzen ein Neutal-Network. Zur Erstellung wir das Deep-Learning Framework Pytorch benutzt.\n",
    "### Ground Truth\n",
    "Als Ground Truth bentzen wir das Modell, welches wir in der Challenge Immobillienrehcner benutzt haben. Mit diesem haben wir die Macro-F1 Score maximiert.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Erstellung Modell Ground Truth"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "csv_data = pd.read_csv('immo_dev_data.csv')\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_fe = csv_data.copy()\n",
    "csv_data_fe['Zip'] = (csv_data_fe['Zip']/100).astype('int8')\n",
    "prepro = preprocessing.preprocessor(csv_data_fe, y_var='GroupNameDe', method_to_encode='onehot_encode', cols_to_drop=['Id', 'LastUpdate', 'Locality', 'StreetAndNr', 'Longitude', 'Latitude', 'HouseObject', 'RealEstateTypeId'], \n",
    "                                    numbers_to_encode=['Zip'], test_frac= 0.1)\n",
    "prepro.preprocess()\n",
    "\n",
    "X_train = prepro.X_train\n",
    "X_test = prepro.X_test\n",
    "\n",
    "y_train = prepro.y_train\n",
    "y_test = prepro.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state = 69)\n",
    "X_random_, y_random_ = ros.fit_resample(X_train, y_train)\n",
    "X_random = X_random_.sample(len(X_train), random_state = 69)\n",
    "y_random = y_random_.iloc[X_random.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc_best = lgb.LGBMClassifier(\n",
    "        n_jobs = -1, seed = 42, learning_rate = 0.07517, max_depth = 340, n_estimators = 344,\n",
    "        num_leaves = 90, reg_alpha = 1.136, reg_lambda = 4.348\n",
    ")\n",
    "\n",
    "lgbc_best.fit(X_random, y_random)\n",
    "lgbc_y_pred_best = lgbc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(sklearn.metrics.classification_report(y_test, knn_y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cuda Device Available\nName of the Cuda Device:  GeForce RTX 3060 Ti\nGPU Computational Capablity:  (8, 6)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Cuda Device Available\")\n",
    "  print(\"Name of the Cuda Device: \", torch.cuda.get_device_name())\n",
    "  print(\"GPU Computational Capablity: \", torch.cuda.get_device_capability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for the model\n",
    "input_dim = X.shape[1]\n",
    "output_dim = 3\n",
    "nr_of_neuros = calc_nr_neuros(X, output_dim, 2)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, nr_of_neuros)\n",
    "        self.b1 = nn.BatchNorm1d(nr_of_neuros)\n",
    "        self.d1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(nr_of_neuros, nr_of_neuros)\n",
    "        self.b2 = nn.BatchNorm1d(nr_of_neuros)\n",
    "        self.d2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(nr_of_neuros, nr_of_neuros)\n",
    "        self.b3 = nn.BatchNorm1d(nr_of_neuros)\n",
    "        self.d3 = nn.Dropout(0.1)\n",
    "        self.fc4 = nn.Linear(nr_of_neuros, nr_of_neuros)\n",
    "        self.b4 = nn.BatchNorm1d(nr_of_neuros)\n",
    "        self.d4 = nn.Dropout(0.1)\n",
    "        self.fc5 = nn.Linear(nr_of_neuros, nr_of_neuros)\n",
    "        self.b5 = nn.BatchNorm1d(nr_of_neuros)\n",
    "        self.d5 = nn.Dropout(0.1)\n",
    "        self.fc6 = nn.Linear(nr_of_neuros, output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.b1(x)\n",
    "        x = self.d1(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.b2(x)\n",
    "        x = self.d2(x)\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.b3(x)\n",
    "        x = self.d3(x)\n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = self.b4(x)\n",
    "        x = self.d4(x)\n",
    "        x = F.leaky_relu(self.fc5(x))\n",
    "        x = self.b5(x)\n",
    "        x = self.d5(x)\n",
    "        x = F.softmax(self.fc6(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falls wir etwas auf der GPU laufen möchten, müssen wir Pytorch explizit sagen, das es das Model und die benötigten Daten auf die GPU schreiben soll:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    y_ohc = pd.get_dummies(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_ohc, test_size=0.2, random_state=42, shuffle = False)\n",
    "    ## To tensors and put them on the gpu:\n",
    "    y_ohc_train_t = torch.tensor(y_train.astype('int8').values).cuda()\n",
    "    X_train_t = torch.tensor(X_train.astype('float32').values).cuda()\n",
    "    y_ohc_test_t = torch.tensor(y_test.astype('int8').values).cuda()\n",
    "    X_test_t = torch.tensor(X_test.astype('float32').values).cuda()\n",
    "else: \n",
    "    NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15000\n",
    "aggregated_losses = []\n",
    "\n",
    "t = trange(EPOCHS)\n",
    "\n",
    "\n",
    "for i in t:\n",
    "\n",
    "    y_pred = model(X_train_t)\n",
    "    single_loss = one_hot_ce_loss(y_pred, y_ohc_train_t)\n",
    "    aggregated_losses.append(single_loss.cpu().detach().numpy())\n",
    "\n",
    "    t.set_description(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  }
 ]
}